#!/bin/bash
STREAMING_TYPE=streaming
MAPRED_JOB_NAME=${JOB_NAME_PREFIX}_preprocess_cjv
#MAPRED_INPUT_PATH=s3a://online-data-pmi/nrt_cjv_snappy/2020-03-3*/*/part-*,s3a://online-data-pmi/nrt_cjv_snappy/2020-04-*/*/part-*,s3a://online-data-pmi/nrt_cjv_snappy/2020-05-*/*/part-*,s3a://online-data-pmi/nrt_cjv_snappy/2020-06-[012]*/*/part-*
#MAPRED_OUTPUT_PATH=${HDFS_WORK_PATH}/click_category/history
#MAPRED_INPUT_PATH=${HDFS_WORK_PATH}/cjv/history
#MAPRED_OUTPUT_PATH=${HDFS_WORK_PATH}/click_category/check
MAPRED_INPUT_PATH=${HDFS_WORK_PATH}/cjv/${DATE_FLAG}
MAPRED_OUTPUT_PATH=${HDFS_WORK_PATH}/click_category/${DATE_FLAG}
# MAPRED_INPUT_PATH=s3a://online-data-pmi/nrt_cjv_snappy/${CJV_DATE_FLAG}/*/part-*
# MAPRED_OUTPUT_PATH=${HDFS_WORK_PATH}/click_category/${DATE_FLAG}
MAPRED_TMP_PATH=${HDFS_TMP_PATH}

MAPPER_CMD="sed -r 's/,/\t/g'"
REDUCER_CMD="python get_click_category.py"

# format
INPUT_FORMAT="org.apache.hadoop.mapred.TextInputFormat"
OUTPUT_FORMAT="org.apache.hadoop.mapred.SequenceFileOutputFormat"

# upload files
CACHE_ARCHIVES=()
UPLOAD_FILES=("${LOCAL_BIN_PATH}/get_click_category.py" "${LOCAL_BIN_PATH}/get_doc_feature.py" "${LOCAL_BIN_PATH}/utils.py")

# task num
MAP_TASKS=300
MAP_TASKS_CAPACITY=300
REDUCE_TASKS=10
REDUCE_TASKS_CAPACITY=10
JOB_PRIORITY=VERY_HIGH
#JOB_QUEUE=profile

# other arguments
ARGUMENTS="-D mapred.max.map.failures.percent=5 -D mapred.reduce.slowstart.completed.maps=0.95 -D mapreduce.jobtracker.split.metainfo.maxsize=-1 -D mapreduce.input.fileinputformat.split.minsize=671088640 -D mapreduce.reduce.memory.mb=5000"
CHECK_OUTPUT="TRUE"
COMPRESS_OUTPUT="TRUE"
