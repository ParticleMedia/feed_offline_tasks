# encoding: utf-8
import urllib
import os
import sys
import json
import time
import random

import basic_types
from basic_types import TrainMode,CatVocab,DiscreteVocab,Feature,Impression,Session,Item

config = {
    "feature_list": [
        Feature(name = "r_did", maxLen = 50, vocabName = "docid", isDocSide = False),
        Feature(name = "r_did_100", maxLen = 50, vocabName = "docid", isDocSide = False),
        Feature(name = "u_pos_chns", maxLen = 24, vocabName = "docpoi", isDocSide = False),
        Feature(name = "u_neg_chns", maxLen = 24, vocabName = "docpoi", isDocSide = False),
        Feature(name = "u_pos_tcat", maxLen = 8, vocabName = "docpoi", isDocSide = False),
        Feature(name = "u_neg_tcat", maxLen = 8, vocabName = "docpoi", isDocSide = False),
        Feature(name = "u_pos_tpcm", maxLen = 8, vocabName = "docpoi", isDocSide = False),
        Feature(name = "u_neg_tpcm", maxLen = 8, vocabName = "docpoi", isDocSide = False),

        Feature(name = "docid", maxLen = 1, vocabName = "docid", isDocSide = True),
        Feature(name = "domain", maxLen = 1, vocabName = "domain", isDocSide = True),
        Feature(name = "d_chns", maxLen = 5, vocabName = "docpoi", isDocSide = True),
        Feature(name = "d_tpc_s", maxLen = 3, vocabName = "docpoi", isDocSide = True),
        Feature(name = "d_tpc_m", maxLen = 3, vocabName = "docpoi", isDocSide = True),
        Feature(name = "d_cats", maxLen = 4, vocabName = "docpoi", isDocSide = True),
    ]
}

def readjson(filename):
    try:
        with open(filename, encoding='utf-8') as fin:
                content = fin.read()
                return json.loads(content)
    except:
        return {}

def tolower(list):
    return [item.lower() for item in list]

def sortDictByValue(d, reverse=True):
    return [item[0] for item in sorted(d.items(), key=lambda item: item[1], reverse=reverse)]

def hasSubCates(cat, catSet):
    for k in catSet:
        if cat != k and k.startswith(cat):
            return True
    return False

def dictToItem(docid, doc_obj):
    raw_d_cats = []
    if "text_category" in doc_obj:
        if "third_cat" in doc_obj["text_category"]:
            raw_d_cats.extend(tolower(sortDictByValue(doc_obj["text_category"]["third_cat"])))
        if "second_cat" in doc_obj["text_category"]:
            raw_d_cats.extend(tolower(sortDictByValue(doc_obj["text_category"]["second_cat"])))
        if "first_cat" in doc_obj["text_category"]:
            raw_d_cats.extend(tolower(sortDictByValue(doc_obj["text_category"]["first_cat"])))
    d_cats = []
    for cat in raw_d_cats:
        match = False
        for d_cat in d_cats:
            if len(d_cat) > len(cat) and d_cat.startswith(cat):
                match = True
                break
        if not match:
            d_cats.append(cat)
    d_chns = tolower(doc_obj["channels"]) if "channels" in doc_obj else []
    d_tpc_s = tolower(sortDictByValue(doc_obj["tpc_s"])) if "tpc_s" in doc_obj else []
    d_tpc_m = tolower(sortDictByValue(doc_obj["tpc_m"])) if "tpc_m" in doc_obj else []

    data = {}
    data["docid"] = [docid]
    data["domain"] = [doc_obj["domain"]]
    data["d_cats"] = d_cats
    data["d_tpc_s"] = d_tpc_s
    data["d_tpc_m"] = d_tpc_m
    data["d_chns"] = d_chns

    item = Item(False, data = data, docid=docid)

    #截断
    for feature in config["feature_list"]:
        if feature.isDocSide:
            x_f = []
            if feature.name in item.data:
                value = item.data[feature.name]
                #TODO: 已经有重复检测了，为了效率考虑这儿暂时不做去重了。
                #长度截断
                x_f = value[-feature.maxLen:] if feature.alignRight else value[:feature.maxLen]
            padding = feature.maxLen - len(x_f)
            if padding > 0:
                #默认值
                x_f = (([feature.defaultValue] * padding) + x_f) if feature.alignRight else (x_f + ([feature.defaultValue] * padding))
            item.data[feature.name] = x_f

    return item

class GetHashCode:
    def __init__(self):
        self.power232 = 2**32
        self.power231 = 2**(32-1)
        self.base = [0] * 200
        for i in range(len(self.base)):
            self.base[i] = 31**i

    #字符串长度超过200时不支持。
    def getHashCode(self,s):
        h = 0
        n = len(s)
        for i, c in enumerate(s):
            h = h + ord(c)* self.base[n-1-i]
        return (h + self.power231) % self.power232 - self.power231

def toTfservingJson(item):
    body = {}
    for feature in config["feature_list"]:
        if feature.isDocSide:
            hash_codes = []
            hash_code_getter = GetHashCode()
            for fea in item.data[feature.name]:
                hash_codes.append(hash_code_getter.getHashCode(fea))
            if feature.isContinuous:
                body['d_{}'.format(feature.name)] = hash_codes
            else:
                body['i_{}'.format(feature.name)] = hash_codes
    ret = {"instances":[body]}
    return ret

def toFeatureJson(item):
    body = {}
    for feature in config["feature_list"]:
        if feature.isDocSide:
            if feature.isContinuous:
                body['d_{}'.format(feature.name)] = item.data[feature.name]
            else:
                body['i_{}'.format(feature.name)] = item.data[feature.name]
    ret = {"instances":[body]}
    return ret

if __name__ == "__main__":
    post_file = sys.argv[1]
    feature_file = sys.argv[2]
    f_post = open(post_file, "a")
    f_feature = open(feature_file, "a")

    for line in sys.stdin:
        line = line.strip()
        if len(line) == 0:
            continue

        splits = line.split('\t')
        if len(splits) != 2:
            continue

        docid = splits[0]
        doc_obj = json.loads(splits[1])
        item = dictToItem(docid, doc_obj)
        if docid != "":
            f_post.write("%s\t%s\n" % (docid, json.dumps(toTfservingJson(item))))
            f_feature.write("%s\t%s\n" % (docid, json.dumps(toFeatureJson(item))))

    f_post.close()
    f_feature.close()

