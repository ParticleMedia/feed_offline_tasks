#!/bin/bash

# hadoop conf
#HADOOP_HOME=/home/work/wangcong07/hadoop-client/hadoop
export HADOOP_CONF_DIR=/home/services/.emr/receng/conf
HADOOP_BIN=hadoop
HDFS_BIN=hdfs
HIVE_BIN="beeline -u jdbc:hive2://receng.emr.nb.com:10000/default -n hadoop"
#HIVE_BIN=hive
HADOOP_UGI=
STREAMING_CMD="jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.16.1.jar"

# hdfs conf
HDFS_ROOT_PATH=s3a://pm-hdfs2/user/wangcong
HDFS_WORK_PATH=${HDFS_ROOT_PATH}/${MODULE_NAME}
HDFS_TMP_PATH=${HDFS_WORK_PATH}/temp

JOB_NAME_PREFIX=wangcong_${MODULE_NAME}
DEFAULT_JOB_QUEUE=profile

DEFAULT_ARGUMENTS="-D mapreduce.map.max.attempts=2 -D mapreduce.reduce.maxattempts=2 -D mapreduce.input.fileinputformat.split.minsize=671088640 -D yarn.app.mapreduce.am.resource.mb=8192 -D mapreduce.job.ubertask.enable=true -D yarn.app.mapreduce.am.command-opts=-Xmx3000m -D fs.s3a.retry.limit=100 -D fs.s3a.retry.interval=1000ms -D fs.s3a.retry.throttle.limit=100 -D fs.s3a.retry.throttle.interval=1s"
